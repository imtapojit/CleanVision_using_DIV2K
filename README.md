# CleanVision using DIV2K : *Deep Learning based Real-Time Denoising, Inpainting, and Restoration of Noisy Images (Computer Vision)*

## ğŸ§  Project Overview

*CleanVision* is a deep learning-powered computer vision project designed to enhance, denoise, and restore degraded images in real time. Leveraging the *DIV2K* dataset, this project focuses on solving three core image restoration challenges: *denoising, **inpainting, and **super-resolution/restoration* using modern neural network architectures.

## ğŸŒŸ Key Features

- ğŸ§¹ Real-time image *denoising* using CNNs or GAN-based models  
- ğŸ–¼ï¸ Intelligent *inpainting* of missing or corrupted image regions  
- ğŸ¨ *Restoration* and super-resolution to enhance visual quality  
- ğŸ“¦ Modular and extensible architecture for training and inference  
- ğŸ“Š Performance evaluation using PSNR, SSIM, and visual comparisons  
- ğŸ§ª Support for custom inputs and real-world test cases  

## ğŸ“‚ Dataset: DIV2K

We use the *DIV2K (DIVerse 2K Resolution)* dataset, a high-quality dataset for image restoration tasks. It contains 2K resolution images with various degradations, making it ideal for:

- Denoising tasks  
- Super-resolution  
- Compression artifact removal  
- Inpainting (custom masks applied)

*Source:* [https://data.vision.ee.ethz.ch/cvl/DIV2K/](https://data.vision.ee.ethz.ch/cvl/DIV2K/)

## ğŸ—ï¸ Model Architectures

- *Denoising*: DnCNN, UNet, or Residual Denoisers  
- *Inpainting*: Partial Convolutional Networks / Masked Autoencoders  
- *Restoration*: SRCNN / ESRGAN for super-resolution  
- *Loss Functions*: MSE, Perceptual Loss, SSIM Loss  
- *Optimizers*: Adam, AdamW with learning rate schedulers

> Optionally supports PyTorch Lightning or Keras for training workflows.

## ğŸ§ª Workflow

1. *Data Preprocessing*  
   - Load and augment DIV2K images  
   - Apply synthetic noise, blur, or masking for training  
2. *Model Training*  
   - Train denoising, inpainting, and restoration models separately  
   - Use early stopping, checkpointing, and logging (TensorBoard/W&B)  
3. *Inference & Visualization*  
   - Pass noisy/damaged images  
   - Visualize original, corrupted, and restored results side by side  

## ğŸ–¼ï¸ Example Use Case

| Input (Noisy) | Cleaned Output |
|---------------|----------------|
| ![noisy](sample_images/noisy.png) | ![clean](sample_images/clean.png) |

## ğŸ”§ Installation & Setup

1. *Clone the repo*
   bash
   git clone https://github.com/imtapojit/CleanVision_using_DIV2K
   cd CleanVision-DIV2K
   

2. *Install dependencies*
   bash
   pip install -r requirements.txt
   

3. *Download and extract DIV2K*
   Place it in the data/ directory or update the path in the config.

4. *Train a model*
   bash
   python train.py --task denoising --model dncnn
   

5. *Run inference*
   bash
   python infer.py --input sample_images/noisy.png --task denoising
   

## ğŸ“Š Evaluation Metrics

- *PSNR* (Peak Signal-to-Noise Ratio)  
- *SSIM* (Structural Similarity Index)  
- *LPIPS* (Used for perceptual quality)

## ğŸ“Œ Folder Structure


CleanVision-DIV2K/
â”œâ”€â”€ data/                  # DIV2K and sample noisy images
â”œâ”€â”€ models/                # Model architectures
â”œâ”€â”€ outputs/               # Saved models, results
â”œâ”€â”€ scripts/               # Utilities, evaluation
â”œâ”€â”€ train.py               # Training script
â”œâ”€â”€ infer.py               # Inference script
â”œâ”€â”€ config.yaml            # Configurations
â””â”€â”€ README.md              # Documentation


## ğŸš€ Future Work

- Add support for real-time webcam/image feed restoration  
- Integrate transformer-based vision models (e.g., ViT, Masked Autoencoders)  
- Train on additional datasets (e.g., BSD500, ImageNet subsets)  
- Add noise/adversarial attack robustness evaluation

## ğŸ¤ Contributions

Contributions are welcome! Feel free to fork the repository, open issues, or submit pull requests for improvements.

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgements

- DIV2K Dataset by CVL ETH Zurich  
- PyTorch / TensorFlow open-source libraries  
- Research inspiration from ESRGAN, DnCNN, and NVIDIAâ€™s inpainting models
